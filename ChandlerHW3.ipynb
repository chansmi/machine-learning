{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "652291d6",
   "metadata": {},
   "source": [
    "# Assignment 3B\n",
    "Chandler Smith\n",
    "\n",
    "Summary: The goal of this project was to explore MLR and logistic regression in depth. This incolved setting up the full ML pipeline, manipulating data, and playing around with the models for optimization. This provided invaluable experience regarding iterating over a model, just like we would if provided a real life problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "212a1396",
   "metadata": {},
   "source": [
    "## House Price MLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d55ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn \n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import missingno as msno\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e779ab56",
   "metadata": {},
   "source": [
    "# Part 1: MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa745b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d31307",
   "metadata": {},
   "source": [
    "## Import House Price for MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11840824",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/Users/chandlersmith/Desktop/CS6140/HW3'\n",
    "os.listdir()\n",
    "\n",
    "# The first column is index: skipping that column\n",
    "ct = pd.read_csv(\"HousePrice.csv\")\n",
    "ct = ct.iloc[:, 1:]\n",
    "ct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e1106",
   "metadata": {},
   "source": [
    "## <font color = darkblue> Multiple Linear Regression (MLR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca158c2",
   "metadata": {},
   "source": [
    "## Variables = Columns:\n",
    "### Numerical Columns\n",
    "OverallQual   TotRmsAbvGrd    BsmtFullBath\n",
    "MasVnrArea      MSSubClass      FullBath        LotArea BedroomAbvGr    Fireplaces      GarageCars      KitchenAbvGr    OverallCond     GarageArea      YearBuilt       PoolArea        \n",
    "\n",
    "### Categorical Columns\n",
    "Neighborhood    BldgType        BsmtExposure    HouseStyle      RoofMatl        KitchenQual     BsmtQual        MSZoning        Heating\n",
    "SaleType        \n",
    "\n",
    "### Targey\n",
    "SalePrice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7251b139",
   "metadata": {},
   "source": [
    "Notes from lecture discussion: Maximize coeff\n",
    "- Predict sale price - standardize, encode categorical, \n",
    "- remove sale price as part of feature space\n",
    "- Increase % coor as much as prossible\n",
    "    - Test, train, split\n",
    "\n",
    "Titanic\n",
    "- Ignore correlation for categorical columns\n",
    "- Should not have 90% percent\n",
    "- Don't standardize the response column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "465d382e",
   "metadata": {},
   "source": [
    "### Creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "# remove NaNs from the table\n",
    "ct2 = ct.dropna()\n",
    "\n",
    "'''Given the independence of each row, it makes sense to remove the NaNs instead of using means or medians.'''\n",
    "\n",
    "# Encode and standardize categorical variables\n",
    "\n",
    "for i in ct2:\n",
    "    if ct2[i].dtype == \"object\":\n",
    "        encode = LabelEncoder()\n",
    "        ct2[i] = encode.fit_transform(ct2[i])\n",
    "# print(ct2.head) # CONF\n",
    "\n",
    "# now all my categorical columns are encoded, yay!\n",
    "# Declaring the response column and the feature space\n",
    "\n",
    "''' iloc indexes data. The first column is an index so we can drop that, and the last column is our target\n",
    " variable which we don't include in our feature space.'''\n",
    "\n",
    "X = ct2.iloc[:, :-1]\n",
    "#print(X)\n",
    "y = ct2[\"SalePrice\"]\n",
    "#print(ct2[\"SalePrice\"])\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# train - test split\n",
    "# Notice the test_size hyperparameter\n",
    "# ----------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76b55abc",
   "metadata": {},
   "source": [
    "### Standardize and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Here, we are performing feature scaling. Passing the data through fit should find the mean and SD of the data. \n",
    "After fitting, we transform the data which means normalizing and scaling. '''\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_stand = scaler.transform(X_train.values)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_stand = scaler.transform(X_test.values)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Train the model\n",
    "# Done in two ways:\n",
    "# Unstandardized features and then standardizae features\n",
    "# ------------------------------------------------------\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#model1 = LinearRegression().fit(X_train, y_train)\n",
    "model2 = LinearRegression().fit(X_train_stand, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1454c3aa",
   "metadata": {},
   "source": [
    "### Printing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Model score, same as coeff of determination = R2\")\n",
    "print(\"Standardized model:\", model2.score(X_test_stand, y_test))\n",
    "print(\"-----------\")\n",
    "\n",
    "print(\"Model hyperparameters\")\n",
    "print(model2.get_params())\n",
    "print(\"-----------\")\n",
    "\n",
    "print(\"Model coefficients: \",model2.coef_)\n",
    "print(\"-----------\")\n",
    "\n",
    "\n",
    "print(\"Model intercept: \",model2.intercept_)\n",
    "print(\"-----------\")\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Coefficient of determination = R2: \",r2_score(y_test, model2.predict(X_test_stand)))\n",
    "print(\"-----------\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE:\",mean_squared_error(y_test,model2.predict(X_test_stand)))\n",
    "print(\"-----------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ad28de8",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "After encoding the categorical columns and standardizing all the data, we ran a train - test split on the model. 1131 rows were used for training, reserving 283 for the test. The result of the model was 0.81 coeff. This is pretty good, however, I think we can do better. I am going to run a pairplot and correlation matrix to see if I can remove a few of the least coorelated columns. This should increase my model score. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c6a0b6d",
   "metadata": {},
   "source": [
    "1) Run pairplots and corrleation matrix to identify columns that are highly associated with Sale Price. \n",
    "\n",
    "The intent of this is to let the feature set present the most associated features to us rather than our bias dominating what we focus on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef815e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pairplots\n",
    "#pairplots is a suit of graphs which compare all features in a matrix\n",
    "# Cite: https://medium.com/@jpeavy09/making-a-pair-plot-using-the-seaborn-library-with-python-bac060479018\n",
    "sns.pairplot(ct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the Sale Price column\n",
    "# This makes it much easier to view a comparison\n",
    "sns.pairplot(ct2, x_vars=['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58838c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Correlation matrix\n",
    "# Visualize it with seaborn\n",
    "# Cite: https://datatofish.com/correlation-matrix-pandas/\n",
    "corr_matrix = ct2.corr()\n",
    "sns.heatmap(corr_matrix, annot=True) \n",
    "sns.heatmap(corr_matrix,annot=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54246ca4",
   "metadata": {},
   "source": [
    "## Improving the model\n",
    "\n",
    "I am going to run a little experiment. My goal is to remove the features that are lowering my models coefficient. To do this, I should be able to calculate the P value for each feature, and then removce the highest one. I will then recalculate the coefficient and if it goes up, yay, but if it goes down, I can put it back in. This process run recursively should yield the highest coefficient. \n",
    "cite: https://machinelearningmind.com/2019/10/14/feature-elimination-using-p-values/\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc285ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# OLS = ordinary least squares\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaler.fit(X)\n",
    "#X = scaler.transform(X.values)\n",
    "X_stand = sm.add_constant(X)\n",
    "\n",
    "OLSmodel = sm.OLS( y, X_stand)\n",
    "results = OLSmodel.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1096027",
   "metadata": {},
   "source": [
    "With the above information, I can clearly see several variable which I can remove, and run again. \n",
    "- SaleType\n",
    "- Heating\n",
    "- MSZoning \n",
    "- BldgType\n",
    "- PoolArea\n",
    "- GarageArea\n",
    "- GarageCars\n",
    "- BedroomAbvGr\n",
    "- MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83762df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_opt = ct2.drop([\"SaleType\", \"Heating\", \"MSZoning\", \"BldgType\", \"PoolArea\", \"GarageArea\",\n",
    "                    \"GarageCars\", \"BedroomAbvGr\", \"MSSubClass\", \"SalePrice\"], axis=1)\n",
    "print(X_opt)\n",
    "y = ct2[\"SalePrice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_stand = scaler.transform(X_train.values)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_stand = scaler.transform(X_test.values)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_Opt = LinearRegression().fit(X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model score, same as coeff of determination = R2\")\n",
    "print(\"Standardized model:\", model_Opt.score(X_test_stand, y_test))\n",
    "print(\"-----------\")\n",
    "\n",
    "print(\"Model hyperparameters\")\n",
    "print(model_Opt.get_params())\n",
    "print(\"-----------\")\n",
    "\n",
    "print(\"Model coefficients: \",model_Opt.coef_)\n",
    "print(\"-----------\")\n",
    "\n",
    "\n",
    "print(\"Model intercept: \",model_Opt.intercept_)\n",
    "print(\"-----------\")\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Coefficient of determination = R2: \",r2_score(y_test, model_Opt.predict(X_test_stand)))\n",
    "print(\"-----------\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE:\",mean_squared_error(y_test,model_Opt.predict(X_test_stand)))\n",
    "print(\"-----------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9137ea42",
   "metadata": {},
   "source": [
    "Well, at the end of the day, the R2 value didn't change much at all. It went from .812 to .816. That being said, the process here produce a faster model, so it is worth going through this process, and further automating it. If I were going to automate it, I would do it one variable at a time to really hone in on the optimal result. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69e3fc1d",
   "metadata": {},
   "source": [
    "# Part 2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92332911",
   "metadata": {},
   "source": [
    "## <font color = darkblue> Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, reg.predict(X_test))\n",
    "\n",
    "# reg.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train_stand, y_train)\n",
    "sgd.score(X_test_stand, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.densify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767f355",
   "metadata": {},
   "source": [
    "## <font color = darkblue>  Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66b41c27",
   "metadata": {},
   "source": [
    "Part 2, the titanic. Here, the response variable will be a binary outcome. Did they survive, or did they not. We will use accuracy to predict this metric. I began this project by using csvkit to convert my txt file to a csv,\n",
    "Command line prompt:\n",
    " - csvformat -T -U 1 Titanic_Passengers.txt > Titanic_Passengers.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7fb98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings and Spouses</th>\n",
       "      <th>Parents and Children</th>\n",
       "      <th>Ticket #</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Port</th>\n",
       "      <th>Lifeboat</th>\n",
       "      <th>Body</th>\n",
       "      <th>Home / Destination</th>\n",
       "      <th>Midpoint age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.34</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.00</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>32.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Passenger Class Survived                                             Name  \\\n",
       "0                1      Yes                    Allen, Miss. Elisabeth Walton   \n",
       "1                1      Yes                   Allison, Master. Hudson Trevor   \n",
       "2                1       No                     Allison, Miss. Helen Loraine   \n",
       "3                1       No             Allison, Mr. Hudson Joshua Creighton   \n",
       "4                1       No  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "\n",
       "      Sex   Age  Siblings and Spouses  Parents and Children Ticket #   Fare  \\\n",
       "0  female 29.00                     0                     0    24160 211.34   \n",
       "1    male  0.92                     1                     2   113781 151.55   \n",
       "2  female  2.00                     1                     2   113781 151.55   \n",
       "3    male 30.00                     1                     2   113781 151.55   \n",
       "4  female 25.00                     1                     2   113781 151.55   \n",
       "\n",
       "     Cabin Port Lifeboat   Body               Home / Destination  Midpoint age  \n",
       "0       B5    S        2    NaN                     St Louis, MO         27.50  \n",
       "1  C22 C26    S       11    NaN  Montreal, PQ / Chesterville, ON          2.50  \n",
       "2  C22 C26    S      NaN    NaN  Montreal, PQ / Chesterville, ON          2.50  \n",
       "3  C22 C26    S      NaN 135.00  Montreal, PQ / Chesterville, ON         32.50  \n",
       "4  C22 C26    S      NaN    NaN  Montreal, PQ / Chesterville, ON         27.50  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first column is index: skipping that column\n",
    "ct = pd.read_csv(\"Titanic_Passengers.csv\")\n",
    "ct = ct.iloc[:, :]\n",
    "ct.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36b3feff",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Upon reviewing my data, I have two problematic columns, life boat and Body. Most of my Body values are NaNs, so I am going to remove Body all together because it wouldn't provide much value. For lifeboat, I don't want to remove it because it probably correlates highly with survival so I am going to change NaNs to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e836af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Yes\n",
      "1       Yes\n",
      "2        No\n",
      "3        No\n",
      "4        No\n",
      "       ... \n",
      "1304     No\n",
      "1305     No\n",
      "1306     No\n",
      "1307     No\n",
      "1308     No\n",
      "Name: Survived, Length: 1306, dtype: object\n",
      "0                         Allen, Miss. Elisabeth Walton\n",
      "1                        Allison, Master. Hudson Trevor\n",
      "2                          Allison, Miss. Helen Loraine\n",
      "3                  Allison, Mr. Hudson Joshua Creighton\n",
      "4       Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\n",
      "                             ...                       \n",
      "1304                               Zabour, Miss. Hileni\n",
      "1305                              Zabour, Miss. Thamine\n",
      "1306                          Zakarian, Mr. Mapriededer\n",
      "1307                                Zakarian, Mr. Ortin\n",
      "1308                                 Zimmerman, Mr. Leo\n",
      "Name: Name, Length: 1306, dtype: object\n",
      "0       female\n",
      "1         male\n",
      "2       female\n",
      "3         male\n",
      "4       female\n",
      "         ...  \n",
      "1304    female\n",
      "1305    female\n",
      "1306      male\n",
      "1307      male\n",
      "1308      male\n",
      "Name: Sex, Length: 1306, dtype: object\n",
      "0        24160\n",
      "1       113781\n",
      "2       113781\n",
      "3       113781\n",
      "4       113781\n",
      "         ...  \n",
      "1304      2665\n",
      "1305      2665\n",
      "1306      2656\n",
      "1307      2670\n",
      "1308    315082\n",
      "Name: Ticket #, Length: 1306, dtype: object\n",
      "0            B5\n",
      "1       C22 C26\n",
      "2       C22 C26\n",
      "3       C22 C26\n",
      "4       C22 C26\n",
      "         ...   \n",
      "1304          0\n",
      "1305          0\n",
      "1306          0\n",
      "1307          0\n",
      "1308          0\n",
      "Name: Cabin, Length: 1306, dtype: object\n",
      "0       S\n",
      "1       S\n",
      "2       S\n",
      "3       S\n",
      "4       S\n",
      "       ..\n",
      "1304    C\n",
      "1305    C\n",
      "1306    C\n",
      "1307    C\n",
      "1308    S\n",
      "Name: Port, Length: 1306, dtype: object\n",
      "0        2\n",
      "1       11\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "1304     0\n",
      "1305     0\n",
      "1306     0\n",
      "1307     0\n",
      "1308     0\n",
      "Name: Lifeboat, Length: 1306, dtype: object\n",
      "0                          St Louis, MO\n",
      "1       Montreal, PQ / Chesterville, ON\n",
      "2       Montreal, PQ / Chesterville, ON\n",
      "3       Montreal, PQ / Chesterville, ON\n",
      "4       Montreal, PQ / Chesterville, ON\n",
      "                     ...               \n",
      "1304                            Unknown\n",
      "1305                            Unknown\n",
      "1306                            Unknown\n",
      "1307                            Unknown\n",
      "1308                            Unknown\n",
      "Name: Destination, Length: 1306, dtype: object\n",
      "(1044, 13)\n",
      "(262, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# impute tools\n",
    "meanImputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "#Clean column title\n",
    "ct2 = ct.rename(columns={'Home / Destination': \"Destination\"})\n",
    "ct2['Destination'].fillna(\"Unknown\", inplace=True)\n",
    "ct2['Destination'] = ct2['Destination'].astype(str)\n",
    "ct2 = ct2.drop(columns=[\"Body\"])\n",
    "ct2.dropna(subset=[\"Port\"], inplace=True)\n",
    "ct2['Lifeboat'].fillna(\"0\", inplace=True)\n",
    "ct2['Lifeboat'] = ct2['Lifeboat'].astype(str)\n",
    "ct2['Cabin'].fillna(\"0\", inplace=True)\n",
    "\n",
    "meanAge = ct2['Age'].mean()\n",
    "ct2['Age'].fillna(meanAge, inplace=True)\n",
    "\n",
    "meanMidpointAge = ct2['Midpoint age'].mean()\n",
    "ct2['Midpoint age'].fillna(meanMidpointAge, inplace=True)\n",
    "\n",
    "ct2.dropna( inplace = True)\n",
    "\n",
    "# Encode and standardize categorical variables\n",
    "for i in ct2:\n",
    "    if ct2[i].dtype == \"object\":\n",
    "        encode = LabelEncoder()\n",
    "        print(ct2[i])\n",
    "        ct2[i] = encode.fit_transform(ct2[i])\n",
    "#print(ct2.head) \n",
    "\n",
    "# Declaring the response column and the feature space\n",
    "\n",
    "X = ct2.iloc[:, ct2.columns != 'Survived']\n",
    "#print(X)\n",
    "y = ct2[\"Survived\"]\n",
    "\n",
    "ct2.to_csv(\"temp.csv\", index=False)\n",
    "\n",
    "# ----------------------------------------\n",
    "# train - test split\n",
    "# Notice the test_size hyperparameter\n",
    "# ----------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train.values)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test.values)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d1a8d",
   "metadata": {},
   "source": [
    "### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "970cf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "caba8658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d5093f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c0af1173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.79231561e-01, 9.64115337e-01, 9.30704365e-01, 1.99457474e-01,\n",
       "       9.84791830e-01, 1.21127641e-05, 2.37495318e-02, 9.56911784e-01,\n",
       "       6.10527280e-02, 9.80723840e-01, 5.49477468e-01, 9.82507596e-01,\n",
       "       8.82707065e-03, 7.91116375e-01, 9.43879286e-01, 2.17217234e-01,\n",
       "       9.95301868e-01, 8.20075053e-04, 7.33525492e-06, 6.94135790e-06,\n",
       "       8.02675045e-01, 6.09285333e-04, 8.14482095e-01, 3.55516667e-04,\n",
       "       9.83350536e-01, 4.26083063e-01, 5.29343625e-05, 9.86837556e-01,\n",
       "       9.58648355e-01, 9.44892395e-06, 9.82174687e-01, 2.62013717e-04,\n",
       "       9.86195217e-01, 8.94948771e-01, 3.02849774e-01, 9.69694539e-01,\n",
       "       4.39376964e-06, 9.47463588e-01, 9.72646592e-01, 9.51462914e-01,\n",
       "       8.19569563e-01, 6.47858486e-03, 2.15222799e-04, 1.18238870e-03,\n",
       "       9.83455533e-01, 9.70659013e-01, 9.80778167e-01, 6.31559419e-05,\n",
       "       5.74622534e-02, 7.36153225e-01, 2.53010981e-01, 9.81656892e-01,\n",
       "       9.77823975e-01, 8.22412731e-01, 1.42215010e-01, 2.86197984e-05,\n",
       "       2.56033716e-05, 9.17719884e-01, 3.15131639e-01, 9.82350586e-01,\n",
       "       9.84648371e-01, 9.75106733e-01, 9.85206017e-01, 9.57591065e-01,\n",
       "       8.13953477e-01, 6.40018728e-01, 9.38743747e-01, 9.64807438e-01,\n",
       "       7.73876040e-01, 6.34909930e-01, 1.53978654e-02, 1.33910807e-02,\n",
       "       1.02185600e-02, 9.82683173e-01, 9.80661159e-01, 3.15549170e-05,\n",
       "       8.60377981e-01, 9.52404240e-01, 9.86938975e-01, 9.80054535e-01,\n",
       "       9.38507373e-01, 9.81614115e-01, 9.77092435e-01, 5.16744298e-01,\n",
       "       9.76228338e-01, 8.41590785e-04, 9.68980955e-01, 7.53630795e-01,\n",
       "       9.09069240e-01, 1.29285553e-04, 9.81310951e-01, 9.71222299e-01,\n",
       "       9.90390831e-01, 7.36262755e-01, 9.78232520e-01, 9.50015130e-01,\n",
       "       9.86926650e-01, 9.68074206e-01, 9.83352017e-01, 8.77533969e-04,\n",
       "       9.30851698e-01, 1.05767150e-02, 9.12990694e-01, 9.66401465e-01,\n",
       "       7.93091087e-01, 1.31758325e-01, 6.42797272e-01, 9.71968166e-01,\n",
       "       4.71374828e-01, 8.89471782e-01, 1.79988209e-01, 9.36614687e-01,\n",
       "       2.59851178e-01, 9.45217707e-01, 9.90887964e-01, 9.78414763e-01,\n",
       "       9.80612273e-01, 6.06398906e-05, 9.80951606e-01, 9.84434473e-01,\n",
       "       9.67330710e-01, 1.20708033e-04, 9.54782478e-01, 9.84534102e-01,\n",
       "       2.86036769e-05, 6.00916997e-02, 9.71537959e-01, 9.86080422e-01,\n",
       "       6.05744309e-07, 9.79484358e-01, 9.77540919e-01, 9.64561407e-01,\n",
       "       1.33779634e-01, 9.83375462e-01, 2.66421273e-04, 9.59635256e-01,\n",
       "       2.69648823e-06, 8.73863359e-01, 9.85617354e-01, 2.70770789e-06,\n",
       "       2.00274362e-01, 1.04816571e-03, 9.00516728e-01, 5.49079276e-01,\n",
       "       9.83797193e-01, 8.86139458e-06, 9.77801241e-01, 9.95518693e-01,\n",
       "       9.81251822e-01, 9.57238948e-01, 9.84392802e-01, 4.50825650e-04,\n",
       "       9.88154412e-01, 9.45188021e-01, 3.23728255e-01, 7.70710406e-01,\n",
       "       3.07954245e-04, 7.37026682e-04, 9.81815457e-01, 1.47050277e-01,\n",
       "       2.36369241e-01, 9.64665165e-01, 9.31683110e-01, 4.69232815e-04,\n",
       "       8.35739192e-06, 9.77765305e-01, 8.92365782e-01, 9.64946086e-04,\n",
       "       8.59882722e-06, 9.85772090e-01, 9.49821509e-01, 9.49652634e-01,\n",
       "       4.58549641e-04, 9.88212574e-01, 1.48993611e-06, 1.33792365e-04,\n",
       "       9.06334095e-01, 4.95095022e-04, 9.75048568e-01, 2.84990896e-05,\n",
       "       9.67017479e-02, 9.39617312e-01, 1.98735170e-01, 9.90092677e-01,\n",
       "       9.49779865e-01, 9.86912462e-01, 9.25536456e-01, 5.98045181e-05,\n",
       "       9.61096679e-01, 9.77583096e-01, 9.32168489e-01, 7.00530253e-01,\n",
       "       9.33959662e-01, 9.87093189e-01, 9.36964413e-01, 1.84273974e-02,\n",
       "       1.96366012e-02, 9.81353650e-01, 9.79750414e-01, 2.00349472e-02,\n",
       "       9.82127333e-01, 9.81807085e-01, 3.78322564e-02, 1.14582050e-03,\n",
       "       2.79339923e-02, 2.21122615e-01, 9.82493242e-01, 1.66055642e-05,\n",
       "       9.83369936e-01, 9.81740267e-01, 6.41789830e-06, 9.53027610e-01,\n",
       "       9.79194150e-01, 9.49310775e-01, 5.42919154e-05, 8.29474120e-01,\n",
       "       9.80447949e-01, 9.85145959e-01, 6.89952373e-06, 8.89965549e-05,\n",
       "       8.65146828e-01, 9.92202968e-01, 6.36248323e-06, 9.42206836e-01,\n",
       "       5.74392185e-06, 9.84687603e-01, 3.73910192e-02, 3.15388390e-01,\n",
       "       9.81747817e-01, 9.79531426e-01, 9.85251323e-01, 9.43216858e-01,\n",
       "       9.78655727e-01, 8.68138253e-01, 3.87675080e-04, 9.79118777e-01,\n",
       "       2.14168525e-01, 1.89477854e-01, 9.72471706e-01, 9.91028998e-01,\n",
       "       9.81431981e-01, 1.95475867e-01, 9.94256176e-01, 8.39364981e-01,\n",
       "       8.33769050e-01, 8.24407572e-01, 2.28692304e-05, 9.31779617e-01,\n",
       "       9.89649345e-01, 9.83589682e-01, 9.75421756e-01, 9.81036182e-01,\n",
       "       6.26214036e-01, 8.28932589e-01, 4.10533399e-03, 1.43120952e-03,\n",
       "       6.40353622e-06, 1.32527929e-01, 2.18940245e-01, 9.86160616e-01,\n",
       "       9.45552943e-01, 9.95007201e-01])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of getting output as 0 - no rain\n",
    "\n",
    "logreg.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2cb990c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.9389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e981b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9521\n",
      "Test set score: 0.9389\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51faf1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9559\n",
      "Test set score: 0.9351\n"
     ]
    }
   ],
   "source": [
    "# fit the Logsitic Regression model with C=100\n",
    "\n",
    "# instantiate the model\n",
    "logreg100 = LogisticRegression(C=100, solver='liblinear', random_state=0)\n",
    "\n",
    "# fit the model\n",
    "logreg100.fit(X_train, y_train)\n",
    "\n",
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg100.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ea667f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[132  25]\n",
      " [ 31  74]]\n",
      "\n",
      "True Positives(TP) =  132\n",
      "\n",
      "True Negatives(TN) =  74\n",
      "\n",
      "False Positives(FP) =  25\n",
      "\n",
      "False Negatives(FN) =  31\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce3ee28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "25de15c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       157\n",
      "           1       0.75      0.70      0.73       105\n",
      "\n",
      "    accuracy                           0.79       262\n",
      "   macro avg       0.78      0.77      0.78       262\n",
      "weighted avg       0.78      0.79      0.79       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "102c9b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;),\n",
       "             param_grid=[{&#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}, {&#x27;C&#x27;: [1, 10, 100, 1000]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;),\n",
       "             param_grid=[{&#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}, {&#x27;C&#x27;: [1, 10, 100, 1000]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=0, solver='liblinear'),\n",
       "             param_grid=[{'penalty': ['l1', 'l2']}, {'C': [1, 10, 100, 1000]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = [{'penalty':['l1','l2']}, \n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logreg,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5,\n",
    "                           verbose=0)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2e8f4f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch CV best score : 0.9531\n",
      "\n",
      "\n",
      "Parameters that give the best results : \n",
      "\n",
      " {'C': 100}\n",
      "\n",
      "\n",
      "Estimator that was chosen by the search : \n",
      "\n",
      " LogisticRegression(C=100, random_state=0, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "# best score achieved during the GridSearchCV\n",
    "print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n",
    "\n",
    "# print parameters that give the best results\n",
    "print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n",
    "\n",
    "# print estimator that was chosen by the GridSearch\n",
    "print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1df3d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch CV score on test set: 0.7863\n"
     ]
    }
   ],
   "source": [
    "# calculate GridSearch CV score on test set\n",
    "\n",
    "print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86ce7a",
   "metadata": {},
   "source": [
    "## <font color = darkblue> Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c54a3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "sns.lineplot(x, y, color = 'red')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f36b998a",
   "metadata": {},
   "source": [
    "## Optimization run\n",
    "Now that I have a baseline result of around 0.72 unstandardized and 0.92 standardized, let's run an elimation method to identify what features in the feature space could be removed to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "692f1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   R-squared:                       0.667\n",
      "Model:                            OLS   Adj. R-squared:                  0.664\n",
      "Method:                 Least Squares   F-statistic:                     199.2\n",
      "Date:                Wed, 22 Feb 2023   Prob (F-statistic):          2.91e-297\n",
      "Time:                        00:49:37   Log-Likelihood:                -191.78\n",
      "No. Observations:                1306   AIC:                             411.6\n",
      "Df Residuals:                    1292   BIC:                             484.0\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.6447      0.053     12.090      0.000       0.540       0.749\n",
      "Passenger Class         -0.0355      0.015     -2.325      0.020      -0.065      -0.006\n",
      "Name                  2.326e-05   2.13e-05      1.091      0.275   -1.86e-05    6.51e-05\n",
      "Sex                     -0.2950      0.018    -16.418      0.000      -0.330      -0.260\n",
      "Age                     -0.0037      0.006     -0.598      0.550      -0.016       0.008\n",
      "Siblings and Spouses    -0.0215      0.008     -2.589      0.010      -0.038      -0.005\n",
      "Parents and Children    -0.0019      0.010     -0.190      0.850      -0.022       0.018\n",
      "Ticket #              1.411e-05   3.04e-05      0.465      0.642   -4.55e-05    7.37e-05\n",
      "Fare                     0.0002      0.000      0.996      0.319      -0.000       0.001\n",
      "Cabin                    0.0004      0.000      2.230      0.026    5.24e-05       0.001\n",
      "Port                    -0.0029      0.010     -0.284      0.777      -0.023       0.017\n",
      "Lifeboat                 0.0371      0.001     33.378      0.000       0.035       0.039\n",
      "Destination             -0.0004   8.36e-05     -4.554      0.000      -0.001      -0.000\n",
      "Midpoint age             0.0004      0.006      0.058      0.953      -0.012       0.012\n",
      "==============================================================================\n",
      "Omnibus:                      151.674   Durbin-Watson:                   1.821\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              233.255\n",
      "Skew:                           0.818   Prob(JB):                     2.24e-51\n",
      "Kurtosis:                       4.269   Cond. No.                     6.36e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.36e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# OLS = ordinary least squares\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaler.fit(X)\n",
    "#X = scaler.transform(X.values)\n",
    "X_stand = sm.add_constant(X)\n",
    "\n",
    "OLSmodel = sm.OLS( y, X_stand)\n",
    "results = OLSmodel.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0138cbcf",
   "metadata": {},
   "source": [
    "According to the above, we should remove the following categories based on high p-values. \n",
    "- Midpoint age\n",
    "- Port\n",
    "- Fare\n",
    "- Ticket Number\n",
    "- Parents and Children\n",
    "- Age\n",
    "- Name\n",
    "\n",
    "Let's try it and see if our accuracy improves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "cf450de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Yes\n",
      "1       Yes\n",
      "2        No\n",
      "3        No\n",
      "4        No\n",
      "       ... \n",
      "1304     No\n",
      "1305     No\n",
      "1306     No\n",
      "1307     No\n",
      "1308     No\n",
      "Name: Survived, Length: 1307, dtype: object\n",
      "0       female\n",
      "1         male\n",
      "2       female\n",
      "3         male\n",
      "4       female\n",
      "         ...  \n",
      "1304    female\n",
      "1305    female\n",
      "1306      male\n",
      "1307      male\n",
      "1308      male\n",
      "Name: Sex, Length: 1307, dtype: object\n",
      "0            B5\n",
      "1       C22 C26\n",
      "2       C22 C26\n",
      "3       C22 C26\n",
      "4       C22 C26\n",
      "         ...   \n",
      "1304          0\n",
      "1305          0\n",
      "1306          0\n",
      "1307          0\n",
      "1308          0\n",
      "Name: Cabin, Length: 1307, dtype: object\n",
      "0        2\n",
      "1       11\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "1304     0\n",
      "1305     0\n",
      "1306     0\n",
      "1307     0\n",
      "1308     0\n",
      "Name: Lifeboat, Length: 1307, dtype: object\n",
      "0                          St Louis, MO\n",
      "1       Montreal, PQ / Chesterville, ON\n",
      "2       Montreal, PQ / Chesterville, ON\n",
      "3       Montreal, PQ / Chesterville, ON\n",
      "4       Montreal, PQ / Chesterville, ON\n",
      "                     ...               \n",
      "1304                            Unknown\n",
      "1305                            Unknown\n",
      "1306                            Unknown\n",
      "1307                            Unknown\n",
      "1308                            Unknown\n",
      "Name: Destination, Length: 1307, dtype: object\n",
      "<bound method NDFrame.head of       Passenger Class  Survived  Sex  Siblings and Spouses  Cabin  Lifeboat  \\\n",
      "0                   1         1    0                     0     43        12   \n",
      "1                   1         1    1                     1     79         3   \n",
      "2                   1         0    0                     1     79         0   \n",
      "3                   1         0    1                     1     79         0   \n",
      "4                   1         0    0                     1     79         0   \n",
      "...               ...       ...  ...                   ...    ...       ...   \n",
      "1304                3         0    0                     1      0         0   \n",
      "1305                3         0    0                     1      0         0   \n",
      "1306                3         0    1                     0      0         0   \n",
      "1307                3         0    1                     0      0         0   \n",
      "1308                3         0    1                     0      0         0   \n",
      "\n",
      "      Destination  \n",
      "0             307  \n",
      "1             229  \n",
      "2             229  \n",
      "3             229  \n",
      "4             229  \n",
      "...           ...  \n",
      "1304          341  \n",
      "1305          341  \n",
      "1306          341  \n",
      "1307          341  \n",
      "1308          341  \n",
      "\n",
      "[1307 rows x 7 columns]>\n",
      "(1045, 6)\n",
      "(262, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "ct = pd.read_csv(\"Titanic_Passengers.csv\")\n",
    "ct = ct.iloc[:, :]\n",
    "\n",
    "# impute tools\n",
    "meanImputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "#Clean column title\n",
    "ct2 = ct.rename(columns={'Home / Destination': \"Destination\"})\n",
    "ct2['Destination'].fillna(\"Unknown\", inplace=True)\n",
    "ct2['Destination'] = ct2['Destination'].astype(str)\n",
    "#ct2 = ct2.drop(columns=[\"Body\"])\n",
    "ct2.dropna(subset=[\"Port\"], inplace=True)\n",
    "ct2['Lifeboat'].fillna(\"0\", inplace=True)\n",
    "ct2['Lifeboat'] = ct2['Lifeboat'].astype(str)\n",
    "ct2['Cabin'].fillna(\"0\", inplace=True)\n",
    "\n",
    "#ct2.dropna( inplace = True)\n",
    "\n",
    "ct2 = ct2.drop(columns=[\"Body\", \"Midpoint age\", \"Port\", \"Fare\", \"Ticket #\", \"Parents and Children\", \"Age\", \"Name\"])\n",
    "\n",
    "\n",
    "# Encode and standardize categorical variables\n",
    "for i in ct2:\n",
    "    if ct2[i].dtype == \"object\":\n",
    "        encode = LabelEncoder()\n",
    "        print(ct2[i])\n",
    "        ct2[i] = encode.fit_transform(ct2[i])\n",
    "print(ct2.head) \n",
    "\n",
    "# Declaring the response column and the feature space\n",
    "\n",
    "X = ct2.iloc[:, ct2.columns != 'Survived']\n",
    "#print(X)\n",
    "y = ct2[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fa2cabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1efe2e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cf514e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90130441, 0.89407951, 0.89250839, 0.90754993, 0.47139273,\n",
       "       0.32225057, 0.83735145, 0.87551852, 0.88223989, 0.90754993,\n",
       "       0.41445079, 0.40699792, 0.85814179, 0.31194224, 0.87723836,\n",
       "       0.40865857, 0.49672125, 0.81725966, 0.26748219, 0.90754993,\n",
       "       0.47560746, 0.90138154, 0.90754993, 0.31000077, 0.90754993,\n",
       "       0.90754993, 0.82416152, 0.9089587 , 0.90754993, 0.32966013,\n",
       "       0.41033121, 0.30656341, 0.91306972, 0.87550027, 0.37403482,\n",
       "       0.90754993, 0.32595408, 0.87556392, 0.90754993, 0.89243096,\n",
       "       0.46718208, 0.85813033, 0.30128261, 0.35076156, 0.9089587 ,\n",
       "       0.32225057, 0.90754993, 0.28171251, 0.88311286, 0.90754993,\n",
       "       0.43769123, 0.90754993, 0.89263669, 0.4629761 , 0.43337455,\n",
       "       0.30542549, 0.28629738, 0.46714359, 0.88771712, 0.31194224,\n",
       "       0.89406678, 0.87557266, 0.47560746, 0.90736415, 0.4629761 ,\n",
       "       0.42588956, 0.89245742, 0.89250517, 0.88586276, 0.46252475,\n",
       "       0.37597051, 0.90725037, 0.83733438, 0.4629761 , 0.90746188,\n",
       "       0.27705561, 0.87707848, 0.87559981, 0.90754993, 0.40458432,\n",
       "       0.8756136 , 0.89584073, 0.89262123, 0.42597505, 0.9087894 ,\n",
       "       0.30707071, 0.9074167 , 0.4629761 , 0.90754993, 0.84409245,\n",
       "       0.4629761 , 0.90754993, 0.90754993, 0.41033121, 0.90754993,\n",
       "       0.87544321, 0.90754993, 0.89570701, 0.90754993, 0.31006496,\n",
       "       0.89260383, 0.46718208, 0.47550181, 0.90736415, 0.9011925 ,\n",
       "       0.43309388, 0.86932194, 0.89419153, 0.91171839, 0.87527936,\n",
       "       0.36525526, 0.46721054, 0.40447574, 0.8754034 , 0.90754993,\n",
       "       0.89257417, 0.90754993, 0.29032049, 0.90754993, 0.90754993,\n",
       "       0.87553196, 0.84700254, 0.8771917 , 0.40292403, 0.30542549,\n",
       "       0.38007995, 0.90738902, 0.43354958, 0.24526919, 0.43354958,\n",
       "       0.90754993, 0.87562398, 0.40284147, 0.9075093 , 0.79885243,\n",
       "       0.90754993, 0.4629761 , 0.85239519, 0.89415335, 0.4629761 ,\n",
       "       0.40286573, 0.30547513, 0.4797921 , 0.42187422, 0.87556392,\n",
       "       0.26796967, 0.90754993, 0.90754993, 0.90754993, 0.87559762,\n",
       "       0.47560746, 0.30492646, 0.90754993, 0.89243096, 0.8879381 ,\n",
       "       0.4629761 , 0.2900906 , 0.315269  , 0.90749914, 0.39869738,\n",
       "       0.40688264, 0.87527941, 0.89235058, 0.81704654, 0.32966013,\n",
       "       0.89411453, 0.87516329, 0.343122  , 0.46718208, 0.84719937,\n",
       "       0.89250065, 0.87549159, 0.31146357, 0.4629761 , 0.25107757,\n",
       "       0.90754993, 0.90754993, 0.81978313, 0.90754993, 0.28527125,\n",
       "       0.39680852, 0.89251936, 0.41405106, 0.90754993, 0.89233507,\n",
       "       0.90754993, 0.87554048, 0.84630443, 0.89246516, 0.90754993,\n",
       "       0.87537496, 0.47560746, 0.87511804, 0.91306972, 0.87740004,\n",
       "       0.40294182, 0.88655823, 0.90754993, 0.90754993, 0.38022572,\n",
       "       0.89584073, 0.4629761 , 0.90754993, 0.31705306, 0.37601626,\n",
       "       0.39887632, 0.90754993, 0.27706649, 0.31480412, 0.90754993,\n",
       "       0.81575496, 0.87550457, 0.90754993, 0.88798357, 0.30542549,\n",
       "       0.4629761 , 0.90754993, 0.90754993, 0.32223442, 0.84630443,\n",
       "       0.87717207, 0.91305958, 0.81575496, 0.89249871, 0.30144142,\n",
       "       0.46718208, 0.89706805, 0.4045794 , 0.90754993, 0.32225057,\n",
       "       0.89253032, 0.87527079, 0.90754993, 0.90754993, 0.90749858,\n",
       "       0.90754993, 0.40940995, 0.90754993, 0.90736076, 0.89264443,\n",
       "       0.89263992, 0.39308183, 0.90754993, 0.4629761 , 0.46718208,\n",
       "       0.4629761 , 0.27732093, 0.87557607, 0.8942564 , 0.90723837,\n",
       "       0.89028484, 0.90754993, 0.88222449, 0.46689588, 0.83743852,\n",
       "       0.35858866, 0.32225057, 0.39307221, 0.43333658, 0.90754993,\n",
       "       0.89254   , 0.90896815])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of getting output as 0 - no rain\n",
    "\n",
    "logreg.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5a2fd310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "807e9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.7748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2203fb9b",
   "metadata": {},
   "source": [
    "## Analysis:\n",
    "\n",
    "The original result of the unstandardized data was a model that produced about a .72 accuracy score. After standardization, this went up to .92, which seems too high. I believe it is too high because I standardized on the categorical data which I had previously encoded, but I am not 100% sure. For the task at hand, identifying what is the combination of deatures that provides the most accurate prediction, it shouldn't matter too much.\n",
    "\n",
    "By removing the following columns based on p_value:\n",
    "- Midpoint age\n",
    "- Port\n",
    "- Fare\n",
    "- Ticket Number\n",
    "- Parents and Children\n",
    "- Age\n",
    "- Name\n",
    "\n",
    "The accuracy on the unstandardized data went up to 0.77 and the standardized data stayed at about .85, which likely points to a failure in my data cleaning. Given the results on the unstandardized data, I believe that removing the columns did improve the overall accuracy of the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "df250b5f6f55ceb2760a6cdcd6e36d176b9e41f612fd931b8243351af70c7aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
